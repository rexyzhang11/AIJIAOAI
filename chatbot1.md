```python
import jieba
```




    '\nJieba分词库一共提供三种模式来进行分词，分别是:精准模式、全模式、搜索引擎模式\n'



Jieba分词库一共提供三种模式来进行分词，分别是:精准模式、全模式、搜索引擎模式

### 精准模式: 
    将句子精确的切开，适合文本分析。通过参数cut_all确定分词模型，如果为False，则为精准模式。


```python
result = jieba.cut("今天天气不错,我来到北京野生动物园,在野生动物园看到有很多凶猛的动物",cut_all=False)
print('精准模式:','|'.join(result)) 
```

    精准模式: 今天天气|不错|,|我|来到|北京|野生|动物园|,|在|野生|动物园|看到|有|很多|凶猛|的|动物
    

### 全模式:
    把句子中所有的可以成词的词语都扫描出来，速度非常快。但是不能解决歧义问题。[cut_all参数的值等于True]


```python
result = jieba.cut( "今天天气不错,我来到北京野生动物园,在野生动物园看到有很多凶猛的动物",cut_all=True)
print('精准模式:','|'.join(result)) 
```

    精准模式: 今天|今天天气|天天|天气|不错|||我|来到|北京|野生|野生动物|生动|动物|动物园|||在野|野生|野生动物|生动|动物|动物园|看到|有|很多|凶猛|的|动物
    

### 搜索引擎模式:
    在精准模式的基础上，对长词再次切分，适用于搜索引擎分词。使用jieba.cut_for_search()方法来实现搜索引擎模式


```python
result = jieba.cut_for_search("今天天气不错,我来到北京野生动物园,在野生动物园看到有很多凶猛的动物")
print('精准模式:','|'.join(result)) 
```

    精准模式: 今天|天天|天气|今天天气|不错|,|我|来到|北京|野生|动物|动物园|,|在|野生|动物|动物园|看到|有|很多|凶猛|的|动物
    


```python
import jieba
from gensim.models import word2vec
f1 = open("fenci.txt",encoding='UTF-8')
#用来储存分词信息
f2 = open("fenci_result.txt","a")

lines = f1.readlines()

for line in lines:
    line.replace("\t","").replace("\n","").replace(" ","")
    seg_list = jieba.cut(line)
    f2.write(" ".join(seg_list))
f1.close()
f2.close()

```


```python
#加载语料库
sentences = word2vec.Text8Corpus("fenci_result.txt")
model = word2vec.Word2Vec(sentences,min_count=1) #语料库太少，min_count必须设置成1，不然会报错

model.save("word2vec.model")

model.wv["我们","贪心"] #获取词向量

```




    array([[ 6.8292907e-04, -4.6044700e-03, -4.2805614e-04, -1.1665163e-03,
            -3.3939267e-03, -1.7453238e-03,  3.7735936e-03, -1.2885723e-03,
             1.9316068e-03, -6.3323422e-04,  4.9021123e-03,  2.0931030e-03,
             3.5042560e-03,  1.3522026e-03, -2.8922823e-03,  1.2758096e-03,
             4.9512237e-03, -1.2722196e-03,  5.1149068e-04, -2.1124133e-03,
             4.7107092e-03,  4.2713931e-04, -1.4716896e-03, -1.5281334e-04,
             8.1637013e-04,  2.3128141e-03, -2.9575515e-03,  3.3364980e-03,
             2.9911909e-03,  1.3388149e-03,  4.5820293e-03, -6.3872029e-04,
             1.8701017e-03,  2.6449033e-03, -3.0844656e-03,  1.8186969e-03,
            -4.1047800e-03, -1.4440705e-03, -4.5836703e-03, -3.9523356e-03,
            -7.6380494e-04, -3.4851886e-03,  3.3312368e-03, -1.6957121e-03,
            -3.1764866e-03, -4.2651533e-03, -1.4535594e-03, -1.7815162e-03,
            -1.4688973e-03,  2.9237459e-03, -2.9271838e-04,  3.2424263e-03,
             3.9272187e-03, -2.6421887e-03, -3.4975477e-03,  3.0793532e-04,
            -3.1294830e-03,  3.8184482e-03, -2.9282428e-03, -1.0480258e-03,
             2.6270235e-03, -4.7303732e-03,  1.0367844e-03, -1.3069338e-03,
             2.7391792e-03, -3.1012942e-03, -1.0543992e-03,  3.7853566e-03,
             2.4691061e-03,  1.7129744e-03, -2.6822116e-04,  2.2503906e-03,
            -2.4854122e-03, -2.5022950e-03, -2.2803217e-03, -2.0935880e-03,
            -1.8087269e-03,  3.6988612e-03, -4.1700678e-04,  4.7086910e-03,
             3.2454950e-03,  3.4050661e-04,  1.4747990e-03, -4.7243601e-03,
             1.7204314e-03,  4.0776818e-03,  7.0527465e-05,  1.0833367e-03,
            -3.0275070e-04, -4.2598778e-03, -1.1353699e-03,  3.1742731e-03,
            -3.9459257e-03, -4.7665145e-03,  6.1386463e-04, -1.7209403e-03,
             3.3688061e-03,  4.8070038e-03, -3.7217336e-03,  8.2110986e-04],
           [-4.7298992e-04,  2.7087186e-03,  4.2186589e-03,  1.0444189e-03,
            -1.1564677e-03,  3.4325740e-03,  4.7335378e-03, -5.5368076e-04,
            -2.6082078e-03,  1.4548913e-03, -1.7900320e-03, -3.7853583e-03,
             4.0835985e-03, -4.2425441e-03, -2.7931069e-03,  4.2140172e-03,
            -1.3105759e-04,  4.2378674e-03,  1.9422775e-03,  3.9871242e-03,
            -3.1135464e-03, -4.8266907e-04,  1.8379091e-03,  2.2049521e-03,
            -1.1999212e-03, -4.0208180e-03,  4.7215587e-03,  1.9026882e-03,
             4.8193275e-03,  1.2749588e-03, -2.2249517e-03,  7.8427634e-04,
            -2.3771350e-04, -1.3725912e-03,  4.2622979e-03, -2.7030236e-03,
             1.8998459e-03,  9.5769146e-04, -3.3811808e-03,  3.2444927e-03,
            -4.2357277e-03, -9.2199579e-04, -2.4126493e-03, -2.8743853e-03,
             2.3636117e-03, -1.0982882e-03,  2.9637946e-03,  4.6965661e-03,
             2.9676086e-03, -2.5537278e-04,  2.9355360e-03,  3.7946245e-03,
            -2.7761392e-03,  4.0778331e-03, -1.7112013e-03,  2.2656133e-03,
             1.4278997e-03, -3.2126573e-03, -1.5808920e-03,  3.7119405e-03,
            -2.4939699e-03, -3.9738719e-03, -1.5617789e-03,  4.0343516e-03,
            -4.8819520e-03,  2.5166227e-03,  5.7035440e-04, -2.1359898e-04,
            -1.6410715e-03,  2.2589210e-03, -4.1986699e-03,  3.7379768e-03,
             1.8748384e-03, -3.8823462e-04,  2.0565339e-03, -3.3682864e-03,
            -2.2448732e-03, -2.0837979e-03, -1.3778772e-03, -1.0995006e-03,
            -3.4506852e-03,  2.8675639e-03, -2.2411686e-03, -6.7529071e-04,
            -3.0138628e-03, -4.0079816e-03, -1.4908068e-03, -2.4253747e-03,
             1.5057870e-03,  2.1182981e-03,  4.8224862e-05, -2.9654901e-03,
            -8.0481917e-04, -4.9075624e-03, -3.5454535e-03,  3.4876687e-03,
            -3.0890410e-03,  2.9763773e-03,  3.2460960e-03, -3.0605530e-03]],
          dtype=float32)



### 欧式距离：
\$$ d= |S_1- S_2|  $$
\
$$ S_1= (x_1,x_2,x_3,..) $$
\
$$ S_2= (y_1,y_2,y_3,..) $$
\
$$ d = \sqrt{(x_1-y_1)^2+(x_2-y_2)^2+...} $$

### 曼哈顿距离:
    两点在轴上的相对距离总和
\
    $$ S_1=(x_1,x_2,..,x_n) $$
\
    $$ S_2=(y_1,y_2,..,y_n) $$
\
    $$ d(S_1,S_2)=|x_1-y_1|+|x_2 -y_2| +...+|x_n -y_n|$$
 

### 余弦相似度:
    余弦相似度的本质是计算两点所构成向量夹角的余弦值, 
\$$ \theta$$
\
    $$ d=\frac {S_1 \cdot S_2} {(|S_1| \times |S_2|)} $$
\
    $$ d=\frac {\sum_{i=1}^n {x_i \times y_i}} {\sqrt{\sum_{i=1}^n x_i^2} \times \sqrt{\sum_{i=1}^n y_i^2}} $$



```python
model.wv.similarity("我们","贪心") #求文本相似度
```




    -0.21994063


